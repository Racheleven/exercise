{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加法进位实验\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/JerrikEph/jerrikeph.github.io/raw/master/Learn2Carry.png\" width=650>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\ts2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\anaconda\\envs\\ts2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\anaconda\\envs\\ts2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\anaconda\\envs\\ts2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\anaconda\\envs\\ts2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\anaconda\\envs\\ts2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "d:\\anaconda\\envs\\ts2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\anaconda\\envs\\ts2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\anaconda\\envs\\ts2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\anaconda\\envs\\ts2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\anaconda\\envs\\ts2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\anaconda\\envs\\ts2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution() # 关键\n",
    "import collections\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import layers, optimizers, datasets\n",
    "import os,sys,tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据生成\n",
    "我们随机在 `start->end`之间采样除整数对`(num1, num2)`，计算结果`num1+num2`作为监督信号。\n",
    "\n",
    "* 首先将数字转换成数字位列表 `convertNum2Digits`\n",
    "* 将数字位列表反向\n",
    "* 将数字位列表填充到同样的长度 `pad2len`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data_batch(batch_size, start, end):\n",
    "    '''在(start, end)区间采样生成一个batch的整型的数据\n",
    "    Args :\n",
    "        batch_size: batch_size\n",
    "        start: 开始数值\n",
    "        end: 结束数值\n",
    "    '''\n",
    "    numbers_1 = np.random.randint(start, end, batch_size)\n",
    "    numbers_2 = np.random.randint(start, end, batch_size)\n",
    "    results = numbers_1 + numbers_2\n",
    "    return numbers_1, numbers_2, results\n",
    "\n",
    "def convertNum2Digits(Num):\n",
    "    '''将一个整数转换成一个数字位的列表,例如 133412 ==> [1, 3, 3, 4, 1, 2]\n",
    "    '''\n",
    "    strNum = str(Num)\n",
    "    chNums = list(strNum)\n",
    "    digitNums = [int(o) for o in strNum]\n",
    "    return digitNums\n",
    "\n",
    "def convertDigits2Num(Digits):\n",
    "    '''将数字位列表反向， 例如 [1, 3, 3, 4, 1, 2] ==> [2, 1, 4, 3, 3, 1]\n",
    "    '''\n",
    "    digitStrs = [str(o) for o in Digits]\n",
    "    numStr = ''.join(digitStrs)\n",
    "    Num = int(numStr)\n",
    "    return Num\n",
    "\n",
    "def pad2len(lst, length, pad=0):\n",
    "    '''将一个列表用`pad`填充到`length`的长度 例如 pad2len([1, 3, 2, 3], 6, pad=0) ==> [1, 3, 2, 3, 0, 0]\n",
    "    '''\n",
    "    lst+=[pad]*(length - len(lst))\n",
    "    return lst\n",
    "\n",
    "def results_converter(res_lst):\n",
    "    '''将预测好的数字位列表批量转换成为原始整数\n",
    "    Args:\n",
    "        res_lst: shape(b_sz, len(digits))\n",
    "    '''\n",
    "    res = [reversed(digits) for digits in res_lst]\n",
    "    return [convertDigits2Num(digits) for digits in res]\n",
    "\n",
    "def prepare_batch(Nums1, Nums2, results, maxlen):\n",
    "    '''准备一个batch的数据，将数值转换成反转的数位列表并且填充到固定长度\n",
    "    Args:\n",
    "        Nums1: shape(batch_size,)\n",
    "        Nums2: shape(batch_size,)\n",
    "        results: shape(batch_size,)\n",
    "        maxlen:  type(int)\n",
    "    Returns:\n",
    "        Nums1: shape(batch_size, maxlen)\n",
    "        Nums2: shape(batch_size, maxlen)\n",
    "        results: shape(batch_size, maxlen)\n",
    "    '''\n",
    "    Nums1 = [convertNum2Digits(o) for o in Nums1]\n",
    "    Nums2 = [convertNum2Digits(o) for o in Nums2]\n",
    "    results = [convertNum2Digits(o) for o in results]\n",
    "    \n",
    "    Nums1 = [list(reversed(o)) for o in Nums1]\n",
    "    Nums2 = [list(reversed(o)) for o in Nums2]\n",
    "    results = [list(reversed(o)) for o in results]\n",
    "    \n",
    "    Nums1 = [pad2len(o, maxlen) for o in Nums1]\n",
    "    Nums2 = [pad2len(o, maxlen) for o in Nums2]\n",
    "    results = [pad2len(o, maxlen) for o in results]\n",
    "    \n",
    "    return Nums1, Nums2, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建模过程， 按照图示完成建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myRNNModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(myRNNModel, self).__init__()\n",
    "        self.embed_layer = tf.keras.layers.Embedding(10, 32, \n",
    "                                                    batch_input_shape=[None, None])\n",
    "        \n",
    "        self.rnncell = tf.keras.layers.SimpleRNNCell(64)\n",
    "        self.rnn_layer = tf.keras.layers.RNN(self.rnncell, return_sequences=True)\n",
    "        self.dense = tf.keras.layers.Dense(10)\n",
    "        \n",
    "    @tf.function\n",
    "    def call(self, num1, num2):\n",
    "        '''\n",
    "        此处完成上述图中模型\n",
    "        '''\n",
    "        num1_embed=self.embed_layer(num1)\n",
    "        num2_embed=self.embed_layer(num2)\n",
    "        input=tf.concat([num1_embed,num2_embed],axis=-1)\n",
    "        output=self.rnn_layer(input)\n",
    "        logits=self.dense(output)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def compute_loss(logits, labels):\n",
    "    losses = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            logits=logits, labels=labels)\n",
    "    return tf.reduce_mean(losses)\n",
    "\n",
    "@tf.function\n",
    "def train_one_step(model, optimizer, x, y, label):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x, y)\n",
    "        loss = compute_loss(logits, label)\n",
    "\n",
    "    # compute gradient\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "def train(steps, model, optimizer):\n",
    "    loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    for step in range(steps):\n",
    "        datas = gen_data_batch(batch_size=200, start=0, end=555555555)\n",
    "        Nums1, Nums2, results = prepare_batch(*datas, maxlen=11)\n",
    "        loss = train_one_step(model, optimizer, tf.constant(Nums1, dtype=tf.int32), \n",
    "                              tf.constant(Nums2, dtype=tf.int32),\n",
    "                              tf.constant(results, dtype=tf.int32))\n",
    "        if step%50 == 0:\n",
    "            print('step', step, ': loss', loss.numpy())\n",
    "\n",
    "    return loss\n",
    "\n",
    "def evaluate(model):\n",
    "    datas = gen_data_batch(batch_size=2000, start=555555555, end=999999999)\n",
    "    Nums1, Nums2, results = prepare_batch(*datas, maxlen=11)\n",
    "    logits = model(tf.constant(Nums1, dtype=tf.int32), tf.constant(Nums2, dtype=tf.int32))\n",
    "    logits = logits.numpy()\n",
    "    pred = np.argmax(logits, axis=-1)\n",
    "    res = results_converter(pred)\n",
    "    for o in list(zip(datas[2], res))[:20]:\n",
    "        print(o[0], o[1], o[0]==o[1])\n",
    "\n",
    "    print('accuracy is: %g' % np.mean([o[0]==o[1] for o in zip(datas[2], res)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(0.001)\n",
    "model = myRNNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function train_one_step at 0x00000224C51971E0> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function train_one_step at 0x00000224C51971E0>: AttributeError: module 'gast' has no attribute 'Str'\n",
      "WARNING: Entity <function train_one_step at 0x00000224C51971E0> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function train_one_step at 0x00000224C51971E0>: AttributeError: module 'gast' has no attribute 'Str'\n",
      "WARNING:tensorflow:Entity <bound method myRNNModel.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x00000224C517ED30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method myRNNModel.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x00000224C517ED30>>: AttributeError: module 'gast' has no attribute 'Str'\n",
      "WARNING: Entity <bound method myRNNModel.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x00000224C517ED30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method myRNNModel.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x00000224C517ED30>>: AttributeError: module 'gast' has no attribute 'Str'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000224C5360840> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000224C5360840>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000224C5360840> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000224C5360840>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method myRNNModel.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x00000224C517ED30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method myRNNModel.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x00000224C517ED30>>: AttributeError: module 'gast' has no attribute 'Str'\n",
      "WARNING: Entity <bound method myRNNModel.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x00000224C517ED30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method myRNNModel.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x00000224C517ED30>>: AttributeError: module 'gast' has no attribute 'Str'\n",
      "WARNING:tensorflow:Entity <function compute_loss at 0x00000224C5197378> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function compute_loss at 0x00000224C5197378>: AttributeError: module 'gast' has no attribute 'Str'\n",
      "WARNING: Entity <function compute_loss at 0x00000224C5197378> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function compute_loss at 0x00000224C5197378>: AttributeError: module 'gast' has no attribute 'Str'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000224C51D8378> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000224C51D8378>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000224C51D8378> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000224C51D8378>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <function train_one_step at 0x00000224C51971E0> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function train_one_step at 0x00000224C51971E0>: AttributeError: module 'gast' has no attribute 'Str'\n",
      "WARNING: Entity <function train_one_step at 0x00000224C51971E0> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function train_one_step at 0x00000224C51971E0>: AttributeError: module 'gast' has no attribute 'Str'\n",
      "step 0 : loss 2.2990818\n",
      "step 50 : loss 1.9163615\n",
      "step 100 : loss 1.9074347\n",
      "step 150 : loss 1.8896649\n",
      "step 200 : loss 1.8873183\n",
      "step 250 : loss 1.8893368\n",
      "step 300 : loss 1.8763266\n",
      "step 350 : loss 1.8813688\n",
      "step 400 : loss 1.8753809\n",
      "step 450 : loss 1.8818337\n",
      "step 500 : loss 1.8735496\n",
      "step 550 : loss 1.8720279\n",
      "step 600 : loss 1.8787801\n",
      "step 650 : loss 1.8669212\n",
      "step 700 : loss 1.8751159\n",
      "step 750 : loss 1.8770152\n",
      "step 800 : loss 1.8700409\n",
      "step 850 : loss 1.8679323\n",
      "step 900 : loss 1.8591521\n",
      "step 950 : loss 1.85518\n",
      "step 1000 : loss 1.8334459\n",
      "step 1050 : loss 1.7864149\n",
      "step 1100 : loss 1.683439\n",
      "step 1150 : loss 1.4868231\n",
      "step 1200 : loss 1.24754\n",
      "step 1250 : loss 1.0266619\n",
      "step 1300 : loss 0.86961955\n",
      "step 1350 : loss 0.7414844\n",
      "step 1400 : loss 0.64823055\n",
      "step 1450 : loss 0.5700327\n",
      "step 1500 : loss 0.49293035\n",
      "step 1550 : loss 0.43390986\n",
      "step 1600 : loss 0.38379133\n",
      "step 1650 : loss 0.33140948\n",
      "step 1700 : loss 0.28797182\n",
      "step 1750 : loss 0.24268843\n",
      "step 1800 : loss 0.20817582\n",
      "step 1850 : loss 0.18510818\n",
      "step 1900 : loss 0.16010845\n",
      "step 1950 : loss 0.13517445\n",
      "step 2000 : loss 0.11977342\n",
      "step 2050 : loss 0.108133614\n",
      "step 2100 : loss 0.09264271\n",
      "step 2150 : loss 0.08434154\n",
      "step 2200 : loss 0.07612166\n",
      "step 2250 : loss 0.06722813\n",
      "step 2300 : loss 0.060815137\n",
      "step 2350 : loss 0.0559799\n",
      "step 2400 : loss 0.05248554\n",
      "step 2450 : loss 0.04707164\n",
      "step 2500 : loss 0.04325669\n",
      "step 2550 : loss 0.03879096\n",
      "step 2600 : loss 0.03764295\n",
      "step 2650 : loss 0.03357286\n",
      "step 2700 : loss 0.032513343\n",
      "step 2750 : loss 0.03036282\n",
      "step 2800 : loss 0.027898591\n",
      "step 2850 : loss 0.025492921\n",
      "step 2900 : loss 0.024271851\n",
      "step 2950 : loss 0.02166068\n",
      "WARNING:tensorflow:Entity <bound method myRNNModel.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x00000224C517ED30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method myRNNModel.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x00000224C517ED30>>: AttributeError: module 'gast' has no attribute 'Str'\n",
      "WARNING: Entity <bound method myRNNModel.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x00000224C517ED30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method myRNNModel.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x00000224C517ED30>>: AttributeError: module 'gast' has no attribute 'Str'\n",
      "1365434903 1365434903 True\n",
      "1449211676 1449211676 True\n",
      "1340128857 1340128857 True\n",
      "1537273300 1537273300 True\n",
      "1625685877 1625685877 True\n",
      "1985741559 1885741559 False\n",
      "1486240387 1486240387 True\n",
      "1259155599 1259155599 True\n",
      "1595878228 1595878228 True\n",
      "1727752123 1727752123 True\n",
      "1597499015 1597499015 True\n",
      "1651795466 1651795466 True\n",
      "1364952685 1364952685 True\n",
      "1333018675 1333018675 True\n",
      "1298157279 1298157279 True\n",
      "1562222932 1562222932 True\n",
      "1452319757 1452319757 True\n",
      "1584627111 1584627111 True\n",
      "1590742599 1590742599 True\n",
      "1186665320 1086665320 False\n",
      "accuracy is: 0.9435\n"
     ]
    }
   ],
   "source": [
    "train(3000, model, optimizer)\n",
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
